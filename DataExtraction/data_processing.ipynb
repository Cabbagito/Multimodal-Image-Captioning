{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIX_DATA_DIR_ORIG = '../Data/Papers'\n",
    "CS10K_DATA_DIR_ORIG = '../Data/CS10K'\n",
    "MIX_DATA_DIR = '../Data/ExtractedData/Mix'\n",
    "CS10K_DATA_DIR = '../Data/ExtractedData/CS10K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(CS10K_DATA_DIR_ORIG):\n",
    "    dir_name = file.split('.')[0]+'.'+file.split('.')[1]\n",
    "    os.mkdir(os.path.join(CS10K_DATA_DIR, dir_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for archive in os.listdir(MIX_DATA_DIR_ORIG):\n",
    "    os.mkdir(os.path.join(MIX_DATA_DIR, archive))\n",
    "    for year in os.listdir(os.path.join(MIX_DATA_DIR_ORIG,archive)):\n",
    "        os.mkdir(os.path.join(MIX_DATA_DIR, archive, year))\n",
    "        for file in os.listdir(os.path.join(MIX_DATA_DIR_ORIG,archive,year)):\n",
    "            dir_name = file.split('.')[0]+'.'+file.split('.')[1]\n",
    "            os.mkdir(os.path.join(MIX_DATA_DIR, archive, year, dir_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_pdf(path):\n",
    "    pdf = fitz.open(path)\n",
    "    page_text = []\n",
    "    page_images = []\n",
    "    for page in pdf:\n",
    "        images = get_imgs_from_page(pdf,page)\n",
    "        text = get_text_from_page(page)\n",
    "        if len(images) != len(text):\n",
    "            continue\n",
    "\n",
    "        page_text.extend(text)\n",
    "        page_images.extend(images)\n",
    "    return page_text, page_images\n",
    "    \n",
    "\n",
    "def get_imgs_from_page(pdf, page):\n",
    "    image_refs = page.get_images()\n",
    "    return [Image.open(io.BytesIO(pdf.extract_image(i[0])['image'])) for i in image_refs]\n",
    "\n",
    "def get_text_from_page(page):\n",
    "    retval = []\n",
    "    blocks = page.get_text('blocks')\n",
    "    for block in blocks:\n",
    "        block = block[4]\n",
    "        if check_block(block):\n",
    "            retval.append(block)\n",
    "    return retval\n",
    "\n",
    "def check_block(block):\n",
    "    if block.startswith('Fig'):\n",
    "        return True\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CS10K\n",
    "files = os.listdir(CS10K_DATA_DIR_ORIG)[8988:]\n",
    "for file in tqdm(files):\n",
    "    try:\n",
    "        dir_name = file.split('.')[0]+ '.'+ file.split('.')[1]\n",
    "        text, images = get_data_from_pdf(os.path.join(CS10K_DATA_DIR_ORIG, file))\n",
    "        json.dump(text, open(os.path.join(CS10K_DATA_DIR,dir_name, 'text.json'), 'w'), indent=4)\n",
    "        for idx, image in enumerate(images):\n",
    "            image.save(os.path.join(CS10K_DATA_DIR,dir_name, f'Image_{idx+1}.png'))\n",
    "    except:\n",
    "        print(f'Error with file: {file}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mix\n",
    "n_errors = 0\n",
    "files = []\n",
    "for archive in os.listdir(MIX_DATA_DIR_ORIG):\n",
    "    for year in os.listdir(os.path.join(MIX_DATA_DIR_ORIG,archive)):\n",
    "        for file in os.listdir(os.path.join(MIX_DATA_DIR_ORIG,archive,year)): \n",
    "            files.append((archive,year,file))\n",
    "                \n",
    "\n",
    "for archive,year,file in tqdm(files):\n",
    "    try:\n",
    "        dir_name = file.split('.')[0]+'.'+file.split('.')[1]\n",
    "        text,images = get_data_from_pdf(os.path.join(MIX_DATA_DIR_ORIG,archive,year,file))\n",
    "        json.dump(text, open(os.path.join(MIX_DATA_DIR,archive, year, dir_name, 'text.json'), 'w'), indent=4)\n",
    "        for idx, image in enumerate(images):\n",
    "            image.save(os.path.join(MIX_DATA_DIR,archive, year, dir_name, f'Image_{idx+1}.png'))\n",
    "    except:\n",
    "        n_errors+=1\n",
    "\n",
    "            \n",
    "print(f'Number of errors: {n_errors}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleted = 0\n",
    "for file in os.listdir(CS10K_DATA_DIR):\n",
    "    if len(os.listdir(os.path.join(CS10K_DATA_DIR, file))) == 1:\n",
    "        shutil.rmtree(os.path.join(CS10K_DATA_DIR, file))\n",
    "        deleted += 1\n",
    "\n",
    "# 9963 total, 4767 deleted, 5196 remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleted = 0\n",
    "for archive in os.listdir(MIX_DATA_DIR):\n",
    "    for year in os.listdir(os.path.join(MIX_DATA_DIR,archive)):\n",
    "        for file in os.listdir(os.path.join(MIX_DATA_DIR,archive,year)):\n",
    "            if len(os.listdir(os.path.join(MIX_DATA_DIR,archive,year,file))) == 1:\n",
    "                deleted += 1\n",
    "                shutil.rmtree(os.path.join(MIX_DATA_DIR,archive,year,file))\n",
    "            \n",
    "print(deleted)\n",
    "\n",
    "# 15516 total, 10802 deleted, 4,714 remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/metadata.json\",'r') as f:\n",
    "    metadata_file = f.readlines()\n",
    "\n",
    "data = []\n",
    "errors = 0\n",
    "for line in tqdm(metadata_file):\n",
    "    try:\n",
    "        data.append(json.loads(line))\n",
    "    except:\n",
    "        errors += 1\n",
    "\n",
    "\n",
    "print(f'Number of lines: {len(metadata_file)}')\n",
    "print(f'Number if extracted: {len(data)}')\n",
    "print(\"Number of errors: \", errors)\n",
    "\n",
    "\n",
    "with open(\"../Data/ExtractedData/metadata.pickle\",\"wb\") as f:\n",
    "    pickle.dump(data,f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/ExtractedData/metadata.pickle\",'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "\n",
    "def find_paper(data, paper_id):\n",
    "    for paper in data:\n",
    "        if paper['id'] == paper_id:\n",
    "            return paper\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [09:58<00:00,  8.68it/s]  \n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(os.listdir(CS10K_DATA_DIR)):\n",
    "    try:\n",
    "        text = json.load(open(os.path.join(CS10K_DATA_DIR, file,'text.json')))\n",
    "    except:\n",
    "        continue\n",
    "    try:\n",
    "        if 'id' in text.keys():\n",
    "            continue\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    paper = find_paper(data,file)\n",
    "    if paper is not None:\n",
    "        json_obj = {\n",
    "            'id': paper['id'],\n",
    "            'title': paper['title'],\n",
    "            'abstract': paper['abstract'],\n",
    "            'text': text\n",
    "        }\n",
    "        with open(os.path.join(CS10K_DATA_DIR, file,'text.json'), 'w') as outfile:\n",
    "            json.dump(json_obj, outfile, indent=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for archive in os.listdir(MIX_DATA_DIR):\n",
    "    print(archive)\n",
    "    for year in os.listdir(os.path.join(MIX_DATA_DIR,archive)):\n",
    "        print(year)\n",
    "        for file in tqdm(os.listdir(os.path.join(MIX_DATA_DIR,archive,year))):\n",
    "            try:\n",
    "                text = json.load(open(os.path.join(MIX_DATA_DIR,archive, year, file,'text.json')))\n",
    "            except:\n",
    "                continue\n",
    "            try:\n",
    "                if 'id' in text.keys():\n",
    "                    continue\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "            paper = find_paper(data,file)\n",
    "            if paper is not None:\n",
    "                json_obj = {\n",
    "                    'id': paper['id'],\n",
    "                    'title': paper['title'],\n",
    "                    'abstract': paper['abstract'],\n",
    "                    'text': text\n",
    "                }\n",
    "                with open(os.path.join(MIX_DATA_DIR,archive, year, file,'text.json'), 'w') as outfile:\n",
    "                    json.dump(json_obj, outfile, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
