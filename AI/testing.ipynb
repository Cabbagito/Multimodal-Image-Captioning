{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "from Data import CS10KDataset, MixDataset\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from rouge_score import rouge_scorer\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CS10KDATA_DIR = \"../Data/ExtractedData/CS10K/\"\n",
    "NUM_BATCHES = 400\n",
    "RESIZE_SHAPE = None\n",
    "VERBOSE = False\n",
    "NUM_WORKERS = 10\n",
    "\n",
    "cs10kdataset = CS10KDataset(CS10KDATA_DIR, NUM_BATCHES, RESIZE_SHAPE, VERBOSE, NUM_WORKERS)\n",
    "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\", truncation_side=\"left\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "feature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "def get_prefix(label):\n",
    "    try:\n",
    "        regex = r\"^(?:Fig(?:ure)?\\.?|Figure:?|Fig\\.?|Figure)\\s*(\\d+)\"\n",
    "        match = re.search(regex, label)\n",
    "        if match:\n",
    "            return match.group(0) if match.group(0) is not None else \"\"\n",
    "    except:\n",
    "        return \"Fig\"\n",
    "\n",
    "def avg(l):\n",
    "    return sum(l) / len(l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge1 = []\n",
    "rouge2 = []\n",
    "rougeL = []\n",
    "f1score = 0\n",
    "for batch in range(60):\n",
    "    print(f'Batch {batch}')\n",
    "    batch = cs10kdataset[len(cs10kdataset) - batch - 1]   \n",
    "    loop = tqdm(batch)\n",
    "    for idx, item in enumerate(loop):\n",
    "        try:\n",
    "            loop.set_description(f'Preparing Inputs\\tRouge Score: {f1score}')\n",
    "            image = item['figure']\n",
    "            if len(image.shape) ==2:\n",
    "                image = np.dstack((image, image, image))\n",
    "            label = item['label']\n",
    "            text = get_prefix(label)\n",
    "            text = '' if text is None else text\n",
    "            inputs = processor(image, text, return_tensors=\"pt\").to(\"cuda\")\n",
    "            loop.set_description(f'Running Model\\tRouge Score: {f1score}')\n",
    "            output = processor.decode(model.generate(**inputs, max_length = len(label),early_stopping=True)[0], skip_special_tokens=True)\n",
    "            loop.set_description(f'Calculating Score\\tRouge Score: {f1score}')\n",
    "            score = scorer.score(label.lower(), output.lower())\n",
    "            rouge1.append(score['rouge1'].fmeasure)\n",
    "            rouge2.append(score['rouge2'].fmeasure)\n",
    "            rougeL.append(score['rougeL'].fmeasure)\n",
    "            f1score = rouge1[-1]\n",
    "        except:\n",
    "            print(f'Error')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
